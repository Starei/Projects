{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b9493e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41928625",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e0be0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eda(X_train, X_test):\n",
    "    # So there are no problems with indexes during cross-validation\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    # Feature extraction\n",
    "    numerical_features = ['Age', 'Debt', 'YearsEmployed', 'ZipCode', 'Income']\n",
    "    categorical_features = [\n",
    "        'Gender', 'Married', 'BankCustomer', 'Industry', 'Ethnicity',\n",
    "        'PriorDefault', 'Employed', 'CreditScore', 'DriversLicense', 'Citizen'\n",
    "    ]\n",
    "    # Logarithmic transformation of a highly skewed variables into a more normalized view\n",
    "    X_train[numerical_features] = np.log(X_train[numerical_features].replace(0, np.nan)).fillna(0)\n",
    "    X_test[numerical_features] = np.log(X_test[numerical_features].replace(0, np.nan)).fillna(0)\n",
    "    return X_train, X_test, numerical_features, categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def preprocessing(X_train, X_test, numerical_features, categorical_features):\n",
    "    # Features Encoding\n",
    "    # Some models are sensitive to scaling of numerical features\n",
    "    numerical_transformer = Pipeline(steps=[('scalar', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[(\n",
    "        'onehot', OneHotEncoder(drop='if_binary', sparse=False, handle_unknown='ignore')\n",
    "    )])\n",
    "\n",
    "    ct = ColumnTransformer([\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    X_train = ct.fit_transform(X_train)\n",
    "    X_test = ct.transform(X_test)\n",
    "    return X_train, X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def model_selection(X, y):\n",
    "    # Starter set of classifiers\n",
    "    classifiers = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'LogReg': LogisticRegression(),\n",
    "        'SVC': SVC(),\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'LGBM': LGBMClassifier(),\n",
    "        'CatBoost': CatBoostClassifier()\n",
    "    }\n",
    "    # Parameters of models for grid search\n",
    "    KNN_grid = {\n",
    "        \"n_neighbors\": list(range(5, 30+1, 5)),\n",
    "        \"weights\": ['uniform', 'distance'],\n",
    "        \"metric\": ['euclidian', 'manhattan', 'minkowski']\n",
    "    }\n",
    "    LogReg_grid = {\n",
    "        \"penalty\": ['l1', 'l2'],\n",
    "        \"C\": [0.001, 0.1, 1, 5, 20],\n",
    "        \"random_state\": [0]\n",
    "    }\n",
    "    SVC_grid = {\n",
    "        \"kernel\": ['poly', 'rbf', 'sigmoid'],\n",
    "        \"C\": [0.001, 0.1, 1, 5, 20],\n",
    "        \"random_state\": [0],\n",
    "        \"probability\": [True]\n",
    "    }\n",
    "    RandomForest_grid = {\n",
    "        \"n_estimators\": [50, 100, 500, 1000],\n",
    "        \"max_features\": ['sqrt', 'log2'],\n",
    "        \"random_state\": [0]\n",
    "    }\n",
    "    LGBM_grid = {\n",
    "        \"n_estimators\": [50, 100, 500, 1000],\n",
    "        \"max_depth\": [3, 6, 9],\n",
    "        \"learning_rate\": [0.001, 0.01, 0.1, 1],\n",
    "        \"random_state\": [0]\n",
    "    }\n",
    "    CatBoost_grid = {\n",
    "        \"n_estimators\": [50, 100, 500],\n",
    "        \"max_depth\": [3, 6, 9],\n",
    "        \"learning_rate\": [0.01, 0.1, 1],\n",
    "        \"random_state\": [0],\n",
    "        \"verbose\": [False]\n",
    "    }\n",
    "\n",
    "    grid = {\n",
    "        'KNN': KNN_grid,\n",
    "        'LogReg': LogReg_grid,\n",
    "        'SVC': SVC_grid,\n",
    "        'RandomForest': RandomForest_grid,\n",
    "        'LGBM': LGBM_grid,\n",
    "        'CatBoost': CatBoost_grid\n",
    "    }\n",
    "    # Models fitting without cross-validation\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)\n",
    "    score = classifiers.copy()\n",
    "    best_params = classifiers.copy()\n",
    "    print(\"MODEL SELECTION\")\n",
    "    for i, (key, classifier) in enumerate(classifiers.items()):\n",
    "        start = time()\n",
    "        clf = GridSearchCV(classifier, param_grid=grid[key], n_jobs=-1, cv=None)\n",
    "        clf.fit(X_train, y_train)\n",
    "        stop = time()\n",
    "        score[key] = clf.score(X_valid, y_valid)\n",
    "        best_params[key] = clf.best_params_\n",
    "        print(\"Model:\", key)\n",
    "        print(\"Score:\", score[key])\n",
    "        print(\"Training time (mins):\", np.round((stop-start)/60, decimals=2))\n",
    "\n",
    "    key_max_score = max(score, key=score.get)\n",
    "    # Choice of best models\n",
    "    best_classifiers = {\n",
    "        key:classifiers[key].set_params(**best_params[key]) for key, value in score.items() if score[key_max_score] - value < 0.015\n",
    "    }\n",
    "    print(\"Best models:\", end=' ')\n",
    "    print(*best_classifiers.keys(), sep=', ')\n",
    "    return best_classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def predictions_tuning(y_test, predictions):\n",
    "    # The Geometric Mean to find optimal threshold\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    best_threshold = thresholds[ix]\n",
    "    predictions[np.where(predictions >= best_threshold)] = 1\n",
    "    predictions[np.where(predictions < best_threshold)] = 0\n",
    "    print(\"Accuracy after tuning:\", accuracy_score(y_test, predictions))\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def prediction(X, y, X_test, y_test, best_classifiers, save_model, filename):\n",
    "    # Soft voting for predictions (Forming an ensemble)\n",
    "    print('*' * 30)\n",
    "    print(\"PREDICITON\")\n",
    "    models = [(key, model) for key, model in best_classifiers.items()]\n",
    "    ensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "    ensemble.fit(X, y)\n",
    "    # To save model\n",
    "    if save_model:\n",
    "        pkl.dump(ensemble, open(filename, 'wb'))\n",
    "    predictions = ensemble.predict_proba(X_test)[:, 1]\n",
    "    print(\"Accuracy before tuning:\", accuracy_score(y_test, predictions.astype(int)))\n",
    "    return predictions_tuning(y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def make_prediction(X_train, X_test, y_train, y_test, save_model, filename=''):\n",
    "    # The main function consisting of the other functions above\n",
    "    X_train, X_test = preprocessing(*eda(X_train, X_test))\n",
    "    best_models = model_selection(X_train, y_train)\n",
    "    return prediction(X_train, y_train, X_test, y_test, best_models, save_model, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make a prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33ea8377",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 590 \n",
      "Test size: 100\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting\n",
    "path_to_train = \"./data/train.csv\"\n",
    "path_to_test = \"./data/test.csv\"\n",
    "filename = \"./models/model.pkl\"\n",
    "save_model = True\n",
    "\n",
    "train = pd.read_csv(path_to_train)\n",
    "test = pd.read_csv(path_to_test)\n",
    "print(\"Train size:\", train.shape[0], \"\\nTest size:\", test.shape[0])\n",
    "\n",
    "X_train, y_train = train.drop('Approved', axis=1), train['Approved']\n",
    "X_test, y_test = test.drop('Approved', axis=1), test['Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SELECTION\n",
      "Model: KNN\n",
      "Score: 0.8108108108108109\n",
      "Training time (mins): 0.26\n",
      "Model: LogReg\n",
      "Score: 0.831081081081081\n",
      "Training time (mins): 0.0\n",
      "Model: SVC\n",
      "Score: 0.8378378378378378\n",
      "Training time (mins): 0.02\n",
      "Model: RandomForest\n",
      "Score: 0.8378378378378378\n",
      "Training time (mins): 0.19\n",
      "Model: LGBM\n",
      "Score: 0.8513513513513513\n",
      "Training time (mins): 0.17\n",
      "Model: CatBoost\n",
      "Score: 0.831081081081081\n",
      "Training time (mins): 1.34\n",
      "Best models: SVC, RandomForest, LGBM\n",
      "******************************\n",
      "PREDICITON\n",
      "Accuracy before tuning: 0.84\n",
      "Accuracy after tuning: 0.9\n",
      "Proportion of True predictions: 0.14\n"
     ]
    }
   ],
   "source": [
    "# To do predictions\n",
    "# And get progress information\n",
    "predictions = make_prediction(X_train, X_test, y_train, y_test, save_model, filename)\n",
    "print(\"Proportion of True predictions:\", predictions.sum() / len(predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score from loaded model: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of the use of the saved model\n",
    "with open(filename, 'rb') as model:\n",
    "    loaded_model = pkl.load(model)\n",
    "    X_train, X_test = preprocessing(*eda(X_train, X_test))\n",
    "    print(\"Score from loaded model:\", loaded_model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "7ea42155",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}